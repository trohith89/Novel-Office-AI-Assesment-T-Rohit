{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Novel Office AI - Assesment"
      ],
      "metadata": {
        "id": "1KQzTahhHhDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŽ¯ Objective:\n",
        "Build an intelligent, high-performance Generative AI chatbot that can deeply understand and interact with the content of a long-form document (100+ pages) using Groq AI."
      ],
      "metadata": {
        "id": "wYSvZ1deHkaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Necessary Libraries"
      ],
      "metadata": {
        "id": "xsA-m8VBLX3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q langchain langchain-community langchain-core langchain-google-genai langchain-groq chromadb groq tiktoken pypdf"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hJ4fg6pxJCT4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“˜ Step 1: Choose a Document**\n",
        "\n",
        "ðŸ“˜ **Document Title for Task Documentation:**\n",
        "- \"Jurisprudenceâ€“I (Legal Method) â€“ LB-101\"\n",
        "- Bachelor of Laws (LL.B.), Ist Term Textbook\n",
        "- Faculty of Law, University of Delhi\n",
        "- Published for the Academic Session 2023\n",
        "- Total Pages: 231\n",
        "- [Public Access Link](https://lawfaculty.du.ac.in/userfiles/downloads/LLBCM/Ist%20Term_Jurisprudence-I_LB101_2023.pdf)"
      ],
      "metadata": {
        "id": "t3On9u62HuZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t_v2Ipob88WK"
      },
      "outputs": [],
      "source": [
        "# Loading the Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/Ist Term_Jurisprudence-I_LB101_2023.pdf\")\n",
        "\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZVHC7Y_Moxh",
        "outputId": "e70d2abb-204d-4eab-996f-f08981660820"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'iLovePDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2023-02-06T11:39:43+00:00', 'source': '/content/Ist Term_Jurisprudence-I_LB101_2023.pdf', 'total_pages': 261, 'page': 0, 'page_label': '1'}, page_content='LL.B. I Term LB-101 - Jurisprudence-I (Legal Method, Indian Legal System and Basic Theories of Law)  Cases Selected and Edited by Mahavir Singh Alka Chawla Anumeha Mishra Amrendra K. Ajit Anita Yadav Ashish Kumar Archa Vashistha Apanjot Kaur Ashutosh Acharya Ajay Sonawane Daya Devi Gurpreet Singh Harleen Kaur Kailash Kurmi Santosh Upadhyay Shakti K Aggarwal Shourie Anand Pushkar Anand Rubina Grewal Nagra Upendra Nath Silky Mukherjee  FACULTY OF LAW UNIVERSITY OF DELHI, DELHI- 110 007   January, 2023  (For private use only in the course of instruction)')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU65yjKLPHNQ",
        "outputId": "fa9cfac5-ef40-49f1-f8a9-d1680b08fc9b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“š Step 2: Splitting Entire Document into Chunks of Document**\n"
      ],
      "metadata": {
        "id": "-kbcY7m2LQBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=250)\n",
        "docs = splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "G5nlLwRAM9-w"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzv7O64PNH6w",
        "outputId": "33c68571-d779-4f5d-da3c-3d6e86b393af"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1223"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“š Step 3: Storing the Embeddings of the Documents in an Venctor Database**\n",
        "- Vector Store: ChromaDB\n",
        "- Embeddings: GoogleGenerativeAIEmbeddings\n"
      ],
      "metadata": {
        "id": "sqUj3HtVN0Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBYBRKYkgZm5OYM1XQYWlrz9psaS3t65Cg\""
      ],
      "metadata": {
        "id": "LEdr39aLPaVR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "jH7mftCgOX2B"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vectordb = Chroma.from_documents(documents=docs, embedding=embedding, persist_directory=\"Chroma_db\")"
      ],
      "metadata": {
        "id": "nXhnBThrP1lJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('Novel_Chroma_DB', 'zip', 'Chroma_db')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "k9B3-FeZbO3c",
        "outputId": "aaf537a3-1191-45fd-8f33-2ee56cb5d1b4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Novel_Chroma_DB.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“š Step 4: Using MMR Retriever(Maximum Marginal Retriever)**\n",
        "\n"
      ],
      "metadata": {
        "id": "vg5NJjR4RJwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mmr_retriever = vectordb.as_retriever(\n",
        "    search_type = \"mmr\",\n",
        "    search_kwargs = {\"k\":3, \"lambda_mult\":1})"
      ],
      "metadata": {
        "id": "PAsQetMVRU34"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“š Step 5: LLM: Groq**\n"
      ],
      "metadata": {
        "id": "hFJDaIBFSMPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "PTWE0z4uSJvx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(temperature=0.3, model_name=\"llama3-70b-8192\")"
      ],
      "metadata": {
        "id": "VA4oxuzTRpU5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beta Testing using A RetreivalQA Chain"
      ],
      "metadata": {
        "id": "TPfVt7cGTcSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. RetrievalQA chain\n",
        "from langchain.chains import RetrievalQA\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                       chain_type=\"stuff\",\n",
        "                                       retriever=mmr_retriever, return_source_documents=True)\n",
        "\n",
        "# 8. Ask questions\n",
        "query = \"Explain Diceyâ€™s Rule of Law as mentioned in the jurisprudence textbook.\"\n",
        "result = qa_chain(query)\n",
        "\n",
        "print(\"Answer:\\n\", result[\"result\"])\n",
        "print(\"\\nSources:\\n\", [doc.metadata['source'] for doc in result[\"source_documents\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhm_t4AwTRE5",
        "outputId": "e3cc8c6c-c35c-475e-f7a3-29a84166469c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " According to the provided context, Dicey's Rule of Law means:\n",
            "\n",
            "1. The absolute supremacy or predominance of regular law, excluding the influence of arbitrary power, prerogative, or wide discretionary authority on the part of the government.\n",
            "\n",
            "2. Equality before the law, or the equal subjection of all classes to the ordinary law courts, excluding the idea of any exemption of officials or others from the duty of obedience to the law which governs other citizens or from the jurisdiction of the ordinary tribunals.\n",
            "\n",
            "In simpler terms, Dicey's Rule of Law means that:\n",
            "\n",
            "* The law is supreme, and arbitrary power or government discretion is not above the law.\n",
            "* Everyone, including government officials, is equal before the law and subject to the same ordinary law courts, with no exemptions.\n",
            "\n",
            "This concept is fundamentally inconsistent with the idea of \"administrative law\" or \"administrative tribunals\" found in foreign countries, where government affairs or disputes are dealt with by special and official bodies outside the civil courts.\n",
            "\n",
            "Sources:\n",
            " ['/content/Ist Term_Jurisprudence-I_LB101_2023.pdf', '/content/Ist Term_Jurisprudence-I_LB101_2023.pdf', '/content/Ist Term_Jurisprudence-I_LB101_2023.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸ“š Step 6: Integrating Langchain Chaining instead of Default Retrival QA Chain**\n",
        "\n",
        "- **Benefits**\n",
        " - Customizable Prompt Template and Output Parsing\n",
        " - allows parallel Chaining for context from retrieved dcouments and LLm output"
      ],
      "metadata": {
        "id": "T2dEptt0X0OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnableParallel, RunnablePassthrough"
      ],
      "metadata": {
        "id": "VJ4jYJzLZUIC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format context function\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Chat Prompt Template\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful and knowledgeable AI assistant specialized in answering questions from a legal textbook.\n",
        "\n",
        "You must use the following information to generate your response:\n",
        "- Use the provided **textbook context**: {context}\n",
        "- If the context does not contain the answer, rely on the **chat history** to infer or clarify.\n",
        "- If neither provides sufficient information, respond honestly that you donâ€™t know.\n",
        "\n",
        "Be clear, concise, and helpful. Do not make up information that is not present in the context or conversation history.\"\"\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "# Chat Model - Groq\n",
        "chat_model = ChatGroq(model_name=\"llama3-70b-8192\", temperature=0.2)\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Runnable Chain Components\n",
        "parallel_chain = RunnableParallel({\n",
        "    \"question\": RunnablePassthrough(),\n",
        "    \"context\": lambda x: format_docs(mmr_retriever.get_relevant_documents(x[\"question\"]))\n",
        "})\n",
        "\n",
        "# Session Memory\n",
        "memory_dict = {\"history\": []}\n",
        "runnable_memory = RunnableLambda(lambda _: memory_dict[\"history\"])\n",
        "\n",
        "# Final Chain\n",
        "final_chain = RunnablePassthrough.assign(chat_history=runnable_memory) | parallel_chain | chat_prompt | chat_model | parser\n",
        "\n",
        "# Conversational Chat Loop\n",
        "while True:\n",
        "    question = input(\"ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): \")\n",
        "    if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"ðŸ‘‹ Bye!\")\n",
        "        break\n",
        "\n",
        "    print(f\"\\nðŸ‘¦ Human: {question}\")\n",
        "    query = {\"question\": question}\n",
        "    response = final_chain.invoke(query)\n",
        "    print(f\"ðŸ¤– AI: {response}\\n\")\n",
        "\n",
        "    memory_dict[\"history\"].append(HumanMessage(content=question))\n",
        "    memory_dict[\"history\"].append(AIMessage(content=response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jridHq8oY3Ub",
        "outputId": "01865ed8-2b0f-41ca-cddd-597c76495a09"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): What is the difference between legal theory and legal philosophy?\n",
            "\n",
            "ðŸ‘¦ Human: What is the difference between legal theory and legal philosophy?\n",
            "ðŸ¤– AI: Based on the provided textbook context, I couldn't find a direct answer to this question. The context primarily focuses on the concepts of law, norms, and their meanings, rather than distinguishing between legal theory and legal philosophy.\n",
            "\n",
            "However, I can try to infer some insights from the context. Hans Kelsen's work, \"Pure Theory of Law,\" seems to be more focused on the theoretical aspects of law, exploring the nature of law, norms, and their meanings. This might be related to legal theory.\n",
            "\n",
            "On the other hand, legal philosophy might be more concerned with the fundamental questions about the nature of law, justice, morality, and their relationships. While Kelsen's work touches on these aspects, it appears to be more focused on the analytical and theoretical framework of law.\n",
            "\n",
            "If I had to make an educated guess, I would say that legal theory might be more concerned with the systematic and structural analysis of law, whereas legal philosophy might be more focused on the underlying principles, values, and concepts that shape our understanding of law and justice.\n",
            "\n",
            "Please note that this is an inference based on the provided context, and a more definitive answer might require additional information or clarification.\n",
            "\n",
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): Hi, my name is rohit\n",
            "\n",
            "ðŸ‘¦ Human: Hi, my name is rohit\n",
            "ðŸ¤– AI: Hi Rohit! It's nice to meet you. I see you've already had a conversation about the difference between legal theory and legal philosophy. I'll make sure to keep that context in mind as we move forward. How can I assist you today? Do you have any follow-up questions or topics you'd like to discuss?\n",
            "\n",
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): what is my name?\n",
            "\n",
            "ðŸ‘¦ Human: what is my name?\n",
            "ðŸ¤– AI: Your name is Rohit.\n",
            "\n",
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): what was my previous question?\n",
            "\n",
            "ðŸ‘¦ Human: what was my previous question?\n",
            "ðŸ¤– AI: Your previous question was \"what is my name?\"\n",
            "\n",
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): and my first question?\n",
            "\n",
            "ðŸ‘¦ Human: and my first question?\n",
            "ðŸ¤– AI: Your first question was \"What is the difference between legal theory and legal philosophy?\"\n",
            "\n",
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): and based on that can you give me further clarity?\n",
            "\n",
            "ðŸ‘¦ Human: and based on that can you give me further clarity?\n",
            "ðŸ¤– AI: Based on our previous conversation, you were seeking clarity on the distinction between legal theory and legal philosophy. I provided an inference based on the provided textbook context, suggesting that legal theory is more concerned with the systematic and structural framework of law, whereas legal philosophy might be more focused on the underlying principles, values, and concepts that shape our understanding of law and justice.\n",
            "\n",
            "To further clarify, the textbook context seems to be more focused on the analytical framework of law, exploring how rules and norms are established, and how they are interpreted in specific cases. This might be related to legal theory. On the other hand, legal philosophy might be more concerned with the fundamental questions about the nature of law, justice, morality, and their relationships, which might not be directly addressed in the provided context.\n",
            "\n",
            "If you have any specific aspects of legal theory or legal philosophy that you'd like me to elaborate on, please feel free to ask, and I'll do my best to provide further clarity.\n",
            "\n",
            "ðŸ’¬ Ask a question about the Jurisprudence textbook (type 'exit' to stop): bye\n",
            "ðŸ‘‹ Bye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iaso1n0qaLd1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}